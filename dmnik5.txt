dmnik5

# ğŸ”¹ Week 1

**Q1. List categorical vs real-valued attributes**

**Steps:**

1. Open Weka â†’ Explorer.
2. Go to **Preprocess tab**.
3. Click **Open file** â†’ load `credit-g.arff` (German Credit dataset).
4. On the left panel, select each attribute â†’ below, Weka shows *Type* (Nominal/Numeric).

   * Nominal = categorical.
   * Numeric = real-valued.

ğŸ‘‰ Write them into 2 lists.

---

# ğŸ”¹ Week 2

**Q2. Crucial attributes & simple rules**

**Steps:**

1. In Explorer â†’ go to **Select attributes tab**.
2. Choose **Attribute Evaluator = InfoGainAttributeEval**.
3. Choose **Search Method = Ranker**.
4. Click **Start**.
5. Weka will rank attributes by importance.

ğŸ‘‰ Use the top-ranked ones to make simple rules (e.g., â€œIf checking\_status = no checking â†’ high chance of bad creditâ€).

---

# ğŸ”¹ Week 3

**Q3. Train Decision Tree (J48) on full data**

**Steps:**

1. Go to **Classify tab**.
2. Choose **Classifier â†’ trees â†’ J48**.
3. Test options â†’ select **Use training set**.
4. Click **Start**.
5. In the results pane:

   * See the **Decision Tree output**.
   * Accuracy on training set is shown.

---

# ğŸ”¹ Week 4

**Q4. Training accuracy & explanation**

**Steps:**

1. Repeat steps of Q3 (J48 with *Use training set*).
2. Note the **Correctly Classified Instances (%)**.
3. Compare to 100% â†’ explain why itâ€™s lower (noise, overlap).

---

# ğŸ”¹ Week 5

**Q5. Cross-validation**

**Steps:**

1. In **Classify tab**.
2. Classifier = **J48**.
3. Test options = **Cross-validation**, folds = 10.
4. Click **Start**.
5. Check accuracy % (slightly lower than training set).

---

# ğŸ”¹ Week 6

**Q6. Reduce attributes**

**Steps:**

1. Go to **Preprocess tab**.
2. Select unwanted attributes â†’ click **Remove**. Keep only attributes: 2, 3, 5, 7, 10, 17, and class.
3. Go to **Classify tab** â†’ J48 â†’ Cross-validation.
4. Click **Start** â†’ Check new accuracy.

---

# ğŸ”¹ Week 7

**Q7. Train with reduced attributes & compare**

**Steps:**

1. Continue from Q6 (reduced attributes dataset).
2. Run J48 with Cross-validation.
3. Compare tree size + accuracy vs full dataset (Q5).

---

# ğŸ”¹ Week 8

**Q8. Simple vs complex Decision Trees (bias vs variance)**

**Steps:**

1. In **Classify tab â†’ J48**.
2. Click on J48 â†’ set **Confidence factor (C)**:

   * Default = 0.25.
   * Try lower (e.g., 0.1) â†’ more complex tree.
   * Try higher (e.g., 0.5) â†’ simpler tree.
3. Run both models â†’ compare tree size + accuracy.

---

# ğŸ”¹ Week 9

**Q9. Reduced Error Pruning**

**Steps:**

1. In **Classify tab â†’ J48**.
2. Click J48 â†’ enable option **-R (Reduced error pruning)**.
3. Test option = **Cross-validation (10 folds)**.
4. Click **Start**.
5. Check pruned tree + accuracy.

---

# ğŸ”¹ Week 10

**Q10. Convert tree to rules / Compare J48, PART, OneR**

**Steps:**

1. **Decision tree to rules (manual)**: Take your J48 output and rewrite splits as â€œifâ€“then rulesâ€.
2. **Train PART classifier**:

   * Classifier = `rules â†’ PART`.
   * Cross-validation (10 folds).
   * Click **Start**.
   * Weka shows rules directly.
3. **Train OneR classifier**:

   * Classifier = `rules â†’ OneR`.
   * Cross-validation.
   * Click **Start** â†’ Weka shows rule based on single attribute.
4. Compare accuracies of J48, PART, OneR.

---

# ğŸ”¹ Week 11

**Q11. K-Means clustering**

**Steps:**

1. Go to **Cluster tab**.
2. Choose **Clusterer â†’ SimpleKMeans**.
3. Click on it â†’ set `numClusters = 2`.
4. Evaluation â†’ select **Classes to clusters evaluation** (so Weka compares clusters with class labels).
5. Click **Start**.
6. Output: cluster assignment + % correctly matched.

---

# ğŸ”¹ Week 12

**Q12. SVM (SMO in Weka)**

**Steps:**

1. Go to **Classify tab**.
2. Choose Classifier = **functions â†’ SMO**.
3. Test option = **Cross-validation (10 folds)**.
4. Click **Start**.
5. Output: Accuracy + confusion matrix.
6. Compare with J48 (Week 5 results).

---

âœ… Thatâ€™s a **clear Weka workflow for all 12 questions**.

Do you want me to also **make a single summary table (Q â†’ Weka Menu Steps â†’ Expected Output)** so you can paste it directly into your report?


OUTPUT
---

## âœ… Week 1

**Q1. List categorical vs. real-valued attributes**

In Weka â†’ *Preprocess tab* â†’ load **credit-g.arff (German Credit Dataset)**.

* Categorical (Nominal) attributes:

  * checking\_status
  * credit\_history
  * purpose
  * savings\_status
  * employment
  * personal\_status
  * debtors
  * property
  * installment\_plans
  * housing
  * job
  * telephone
  * foreign\_worker

* Real-valued (Numeric) attributes:

  * duration
  * credit\_amount
  * residence\_since
  * age
  * existing\_credits
  * num\_dependents

ğŸ‘‰ Output in Weka: Attribute type (Nominal/Numeric) is shown in the **Preprocess tab**.

---

## âœ… Week 2

**Q2. Crucial attributes & rules**

By domain knowledge + attribute importance (InfoGain in Weka â†’ *Select attributes* tab):

* Crucial attributes: checking\_status, credit\_history, savings\_status, purpose, age, credit\_amount.

ğŸ‘‰ Example simple rules (plain English):

* If checking\_status = "no checking" **and** credit\_amount > 5000 â†’ credit = *bad*.
* If savings\_status = "500+ savings" **and** credit\_history = "good" â†’ credit = *good*.

---

## âœ… Week 3

**Q3. Train Decision Tree**

Steps:

* Classify tab â†’ choose `J48` â†’ Test options: *Use training set* â†’ Start.

ğŸ‘‰ Example tree output (simplified):

```
checking_status = <0 DM
| credit_history = critical/other existing credit â†’ bad
| credit_history = existing paid â†’ good
checking_status = no checking
| savings_status = <100 DM â†’ bad
| savings_status = 500+ DM â†’ good
```

Weka shows the full tree + number of leaves + size.

---

## âœ… Week 4

**Q4. Training accuracy**

* Using *Use training set* â†’ Accuracy â‰ˆ **80â€“85%**.
* Not 100% because:

  * Noise in data.
  * Overlapping attribute values.
  * Some customers with same attributes behave differently.

---

## âœ… Week 5

**Q5. Cross-validation**

* In *Classify tab* â†’ choose `10-fold cross-validation`.
* Accuracy drops slightly (\~72â€“76%).

ğŸ‘‰ Why? Training set accuracy was **overfitted**. Cross-validation gives a more realistic estimate of generalization performance.

---

## âœ… Week 6

**Q6. Reduce attributes**

Try subset (e.g., attributes 2, 3, 5, 7, 10, 17 + class):

* credit\_history
* purpose
* employment
* debtors
* housing
* age
* class

ğŸ‘‰ In Weka: remove other attributes in *Preprocess tab*.

* Train J48 with reduced attributes â†’ Accuracy \~70â€“73%.
* Still reasonable, so not all 20 attributes are needed.

---

## âœ… Week 7

**Q7. Compare trees with reduced attributes**

* Decision Tree (reduced attributes) is **smaller** and easier to interpret.
* Accuracy slightly decreases (\~70% vs. 72â€“76%).
* Cross-validation results close, so simplification is worth it.

---

## âœ… Week 8

**Q8. Simple vs complex decision trees**

* Simple trees: easier to interpret, less overfitting â†’ higher bias but lower variance.
* Complex trees: may memorize data (overfitting).
* In Weka â†’ Compare tree depth parameter (`-C` confidence factor) â†’ smaller CF = bigger tree.

ğŸ‘‰ Trade-off: Complexity â†‘ â†’ bias â†“ but variance â†‘.

---

## âœ… Week 9

**Q9. Pruning (Reduced Error Pruning)**

* In Weka: `weka.classifiers.trees.J48 -R` (pruning enabled).
* Output tree is smaller (fewer branches).
* Accuracy \~74â€“77% (slightly better than unpruned).

ğŸ‘‰ Explanation: Pruning removes noisy/unnecessary splits â†’ better generalization.

---

## âœ… Week 10

**Q10. Convert tree to rules**

* Small tree example:

```
If checking_status = no checking AND savings_status = <100 â†’ bad
If checking_status = no checking AND savings_status = >=500 â†’ good
Else â†’ good
```

* In Weka: Use `rules.PART`.

* PART outputs set of â€œif-thenâ€ rules (simpler than tree).

* In Weka: Use `rules.OneR`.
  Example OneR rule:

  ```
  If checking_status = <0 â†’ bad
  If checking_status = no checking â†’ good
  ...
  ```

* Ranking accuracy (typical):

  * J48 â‰ˆ 72â€“76%
  * PART â‰ˆ 73â€“77%
  * OneR â‰ˆ 65â€“70%

---

## âœ… Week 11

**Q11. K-Means clustering**

* In *Cluster tab* â†’ choose `SimpleKMeans`, set k=2 (good/bad credit).
* Accuracy not directly given (unsupervised), but you can evaluate using â€œClasses to clusters evaluationâ€.
* Usually \~65â€“70% match with true labels.

ğŸ‘‰ Justification: Customers group into risky vs safe clusters, but not perfectly aligned with labels.

---

## âœ… Week 12

**Q12. SVM classification**

* In *Classify tab* â†’ choose `SMO` (Wekaâ€™s SVM).
* 10-fold cross-validation accuracy â‰ˆ **75â€“78%**.

ğŸ‘‰ Compare:

* Decision Tree (J48): 72â€“76%
* SVM (SMO): 75â€“78% (slightly better, more robust).

---

âœ… That covers **all 12 questions with Weka outputs + interpretations**.

TABLE

Great ğŸ‘ Hereâ€™s the **single summary table** with **Q â†’ Weka Menu Steps â†’ Expected Output** for all 12 questions.

---

# ğŸ“Š Weka Steps & Outputs Summary

| Week / Q      | Weka Steps                                                                                                                                                               | Expected Output / Notes                                                                                            |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------ |
| **W1 â€“ Q1**   | Preprocess â†’ Open `credit-g.arff` â†’ Select each attribute â†’ check â€œTypeâ€ (Nominal/Numeric)                                                                               | List categorical (Nominal) vs real-valued (Numeric) attributes                                                     |
| **W2 â€“ Q2**   | Select attributes â†’ Evaluator = `InfoGainAttributeEval` â†’ Search = `Ranker` â†’ Start                                                                                      | Ranked list of important attributes â†’ write simple English rules                                                   |
| **W3 â€“ Q3**   | Classify â†’ Classifier = `trees â†’ J48` â†’ Test option = *Use training set* â†’ Start                                                                                         | Decision Tree model printed; Training accuracy â‰ˆ 80â€“85%                                                            |
| **W4 â€“ Q4**   | Same as Q3                                                                                                                                                               | Accuracy < 100% (noise, overlapping attributes)                                                                    |
| **W5 â€“ Q5**   | Classify â†’ J48 â†’ Test option = *Cross-validation (10 folds)* â†’ Start                                                                                                     | Accuracy â‰ˆ 72â€“76% (realistic estimate, lower than training set)                                                    |
| **W6 â€“ Q6**   | Preprocess â†’ Remove unwanted attributes â†’ Keep only (2,3,5,7,10,17,class) â†’ Classify â†’ J48 â†’ Cross-validation â†’ Start                                                    | Smaller tree; Accuracy â‰ˆ 70â€“73%                                                                                    |
| **W7 â€“ Q7**   | Repeat Q6 with reduced attributes                                                                                                                                        | Compare with full dataset â†’ simpler tree, slightly lower accuracy                                                  |
| **W8 â€“ Q8**   | Classify â†’ J48 â†’ Change confidence factor (C) values: 0.1 (complex), 0.5 (simple) â†’ Start                                                                                | Shows bias-variance tradeoff; simpler tree = higher bias, less variance                                            |
| **W9 â€“ Q9**   | Classify â†’ J48 â†’ Enable option `-R` (Reduced Error Pruning) â†’ Cross-validation                                                                                           | Smaller pruned tree; Accuracy â‰ˆ 74â€“77% (often better than unpruned)                                                |
| **W10 â€“ Q10** | (1) Take J48 tree â†’ manually write ifâ€“then rules; (2) Classifier = `rules â†’ PART` â†’ Cross-validation â†’ Start; (3) Classifier = `rules â†’ OneR` â†’ Cross-validation â†’ Start | PART outputs rules; OneR gives single-attribute rule; Accuracy ranking: J48 \~72â€“76%, PART \~73â€“77%, OneR \~65â€“70% |
| **W11 â€“ Q11** | Cluster â†’ `SimpleKMeans` â†’ numClusters=2 â†’ Classes-to-clusters evaluation â†’ Start                                                                                        | Clusters formed; \~65â€“70% match with true labels                                                                   |
| **W12 â€“ Q12** | Classify â†’ Classifier = `functions â†’ SMO` (SVM) â†’ Cross-validation â†’ Start                                                                                               | Accuracy â‰ˆ 75â€“78%; Compare with J48 (72â€“76%)                                                                       |

---

âš¡ This table is concise enough for your **report submission** while still giving the **step-by-step procedure**.

Do you also want me to prepare a **ready-to-use â€œResults & Discussionâ€ section** (answers written in paragraph style for each week), so you can just paste it into your assignment report?
