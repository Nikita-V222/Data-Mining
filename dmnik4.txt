dmnik4

# ðŸ”¹ Detailed Steps in Weka for Each Question

---

### **Q1: List categorical & real-valued attributes**

1. Open **Weka â†’ Explorer â†’ Preprocess**.
2. Load dataset (`credit-g.arff` or your `.csv` converted to `.arff`).
3. On the **Preprocess panel**, you will see all attributes listed.

   * Nominal attributes show possible values (e.g., *checking\_status = {<0, 0â‰¤X<200, â‰¥200}*).
   * Numeric attributes show only type "numeric".
4. Note down:

   * **Categorical (Nominal):** checking\_status, credit\_history, purpose, savings\_status, employment, personal\_status, property, installment\_plans, housing, job, telephone, foreign\_worker, residence.
   * **Numeric (Real-valued):** duration, credit\_amount, age, existing\_credits, num\_dependents.

âœ… Output: Attribute separation list.

---

### **Q2: Crucial attributes & simple rules**

1. Stay in **Preprocess â†’ Visualize All** to view scatter plots and histograms.
2. Attributes that strongly separate classes (good/bad credit) are *credit\_history, checking\_status, duration, credit\_amount*.
3. Simple English rules example:

   * If `checking_status = no checking` **AND** `credit_history = poor` â†’ likely *bad credit*.
   * If `credit_history = good` **AND** `duration < 12 months` â†’ likely *good credit*.

âœ… Output: Rules (manually interpreted).

---

### **Q3: Train a Decision Tree**

1. Go to **Classify â†’ Choose â†’ trees â†’ J48** (Wekaâ€™s C4.5 decision tree).
2. Use **Use training set**.
3. Click **Start**.
4. Output will show:

   * Decision tree structure.
   * Training accuracy (will be high, \~80â€“85%).

âœ… Output: Full J48 tree + accuracy %.

---

### **Q4: Evaluate on training data**

1. Already done in Q3 (using **Use training set**).
2. Weka output shows **Correctly Classified Instances = XX%**.

   * Expect around 85%.
3. Reason not 100%: **overfitting avoidance, noise in data, real-world uncertainty**.

âœ… Output: Accuracy % + reasoning.

---

### **Q5: Cross-validation**

1. In **Classify tab**, select **Cross-validation** â†’ 10 folds.
2. Run J48 again.
3. Compare accuracy with Q3.

   * Training set accuracy (Q3) is usually higher.
   * Cross-validation accuracy is realistic (\~70â€“75%).

âœ… Output: Cross-validation accuracy + comparison with training.

---

### **Q6: Reduce attributes**

1. In **Preprocess tab**, uncheck all except attributes 2, 3, 5, 7, 10, 17 (and class).
2. Run **Classify â†’ J48** again.
3. Compare accuracy with full dataset.

   * Accuracy usually drops slightly but remains decent.

âœ… Output: Accuracy with reduced attributes.

---

### **Q7: Train with reduced vs full attributes**

1. Run Decision Tree with:

   * Full attributes (Q5).
   * Reduced attributes (Q6).
2. Compare **tree size, rules generated, and accuracy**.
3. Report difference: smaller trees, sometimes slightly less accurate, but easier to interpret.

âœ… Output: Accuracy comparison table.

---

### **Q8: Simple vs complex trees**

1. In **J48 options**, set:

   * `-C` (confidence factor) â†’ lower value (e.g., 0.05) â†’ larger complex tree.
   * Higher value (e.g., 0.5) â†’ simpler pruned tree.
2. Run with both settings.
3. Compare complexity vs accuracy.

   * Simple tree = higher bias, lower variance.
   * Complex tree = lower bias, risk of overfitting.

âœ… Output: Accuracy + interpretation.

---

### **Q9: Reduced Error Pruning**

1. Go to **Classify â†’ trees â†’ ReducedErrorPruningTree (REPTree)**.
2. Choose **10-fold CV**.
3. Run and record accuracy.
4. Compare with unpruned J48.

   * Usually accuracy improves or stays similar, tree size reduces.

âœ… Output: Accuracy + pruned tree results.

---

### **Q10: Convert Decision Tree to Rules**

1. Use **Classify â†’ rules â†’ PART**.

   * Output shows â€œifâ€“thenâ€ rules directly.
2. Use **Classify â†’ rules â†’ OneR**.

   * Selects the best single attribute and outputs one rule (e.g., *checking\_status â†’ good/bad*).
3. Compare accuracy:

   * J48 > PART > OneR (usually).

âœ… Output: Rules + accuracy + ranking.

---

### **Q11: K-means clustering**

1. Go to **Cluster â†’ Choose â†’ SimpleKMeans**.
2. Set **Number of clusters = 2** (good/bad).
3. Run clustering.
4. Weka output:

   * Cluster centroids for numeric attributes.
   * Distribution of categorical attributes.
5. Manually map clusters to class labels (compare with actual good/bad).

âœ… Output: Cluster centroids + % cluster assignment.

---

### **Q12: SVM vs Decision Tree**

1. Go to **Classify â†’ functions â†’ SMO (Support Vector Machine)**.
2. Run with **10-fold cross-validation**.
3. Compare accuracy with Decision Tree (Q5).

   * SVM usually \~75â€“80% accuracy, sometimes better than J48.

âœ… Output: Accuracy of SMO vs J48.

---

# ðŸ“Š Example Output Snapshot (Typical Results)

* J48 Training Accuracy: \~85%
* J48 Cross-validation: \~72â€“75%
* Reduced attributes: \~70â€“73%
* PART rules: \~74%
* OneR rules: \~63%
* KMeans clustering: matches \~65â€“70% with class
* SMO (SVM): \~78â€“80%

---

ðŸ‘‰ Would you like me to prepare a **ready-made results table** (with placeholders for you to fill in Wekaâ€™s exact % values after running) so you can directly submit it in your lab report?
